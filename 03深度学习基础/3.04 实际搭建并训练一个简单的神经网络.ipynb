{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际搭建并训练一个简单的神经网络\n",
    "\n",
    "作者：杨岱川\n",
    "\n",
    "时间：2019年12月\n",
    "\n",
    "github：https://github.com/DrDavidS/basic_Machine_Learning\n",
    "\n",
    "开源协议：[MIT](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/LICENSE)\n",
    "\n",
    "参考文献：\n",
    "\n",
    "- 《深度学习入门》，作者：斋藤康毅；\n",
    "- 《深度学习》，作者：Ian Goodfellow 、Yoshua Bengio、Aaron Courville。\n",
    "- [Keras overview](https://tensorflow.google.cn/guide/keras/overview)\n",
    "- [PYTORCH TUTORIALS](https://pytorch.org/tutorials/)\n",
    "\n",
    "### 学习回顾\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们学习了如何搭建一个三层的全连接神经网络，并且实现了它的前向传播过程。\n",
    "\n",
    "在 [3.02 神经网络的训练](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.02%20神经网络的训练.ipynb)中，我们主要学习了如何使用数值微分的方法计算神经网络的梯度，并通过随机梯度下降法去优化神经网络的参数。\n",
    "\n",
    "在 [3.03 误差反向传播法](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.03%20误差反向传播法.ipynb)中，我们主要学习了计算图的原理，以及如何使用计算图的**反向传播**高效地计算导数，并且实现了加法乘法以及部分简单函数的反向传播推导。\n",
    "\n",
    "可以说到目前为止，全连接神经网络的最重要的几个数学原理我们已经有部分概念了。可能你记不得具体某个公式怎么写，某个函数怎么编程，这些都没有关系。关键在于，你知道这些名词的**概念**和用途，并且你知道有朝一日要在实际工作和科研中运用的时候去哪里**查询**具体用法。\n",
    "\n",
    "熟练来自于长期的积累，我们现在只走出了第一步。\n",
    "\n",
    "### 学习目标\n",
    "\n",
    "在上述三份 notebook 中，我们基本都是用 Python 亲手实现了前向传播和反向传播的各个过程和结构。但是在实际科研和工作中，我们并没有如此多的时间或精力去 “手写” 这么一份网络结构代码。\n",
    "\n",
    "更常见的情况是，我们会使用各种成熟的深度学习框架系统来完成对网络结构的搭建，比如大家熟悉的 TensorFlow2.0 或者 PyTorch 。\n",
    "\n",
    "对于这两个框架我就不多介绍了，我们在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中已经有过初步接触。不过那时候我们只是实现了一个最简单的三层全连接神经网络，然后实验了一下前向传播的计算过程，并没有涉及训练和优化等更多内容。\n",
    "\n",
    "在学习了 “随机梯度下降法” 和 “误差反向传播” 法地理论基础以后，我们终于可以正式地在深度学习框架中运用这些方法技巧，完成训练。\n",
    "\n",
    "本章节的目标就是：**运用深度学习框架搭建一个神经网络模型，实现对简单数据集的训练和预测。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch - 数据集准备\n",
    "\n",
    "### MNIST 数据集\n",
    "\n",
    "首先向大家介绍 [MNIST 手写数字数据集](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 手写数字数据集在机器学习界可以说是无人不知无人不晓。美国国家标准与技术研究院（National Institute of Standards and Technology，NIST），而 MNIST 就是 “Modified National Institute of Standards and Technology” 的缩写。\n",
    "\n",
    "此数据集自1999年发布以来，已经成为了图像分类领域的基础数据集。随着技术不断进步，各种新分类方法不断出现，MNIST 数据集成为了检验这些方法的常用数据集之一。\n",
    "\n",
    "MINIST实验包含了四个文件，其中`train-images-idx3-ubyte`是 60000 个图片样本，`train-labels-idx1-ubyte`是这 60000 个图片对应的数字标签，`t10k-images-idx3-ubyte` 是用于测试的样本，`t10k-labels-idx1-ubyte` 是测试样本对应的数字标签。\n",
    "\n",
    "这份数据集采集自美国人口调查局的员工和高中生，内容为 0-9 一共十个数字的手写体。我们的任务就是从成千上万的数字中训练并构建一个模型，能识别这些图像中的手写数字。\n",
    "\n",
    "MNIST的图像数据是28像素×28像素的灰度图像（1通道），各个像素的取值在0到255之间。每个图像都相应地标有“1”、“2”、“3”等标签。\n",
    "\n",
    "很多框架中已经内置了 MNIST 数据集，调用十分方便：\n",
    "\n",
    "- TensorFlow：[tfds.image.mnist.MNIST](https://tensorflow.google.cn/datasets/catalog/mnist?hl=en)\n",
    "- PyTorch：[torchvision.datasets.MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST)\n",
    "\n",
    "\n",
    "### 下载 MNIST 数据集\n",
    "\n",
    "在 MNIST 数据集官网可以直接下载数据集：http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "共有四个文件，如下：\n",
    "\n",
    "```\n",
    "- train-images-idx3-ubyte.gz:  training set images (9912422 bytes) \n",
    "- train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) \n",
    "- t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) \n",
    "- t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n",
    "```\n",
    "\n",
    "四个文件夹以压缩文件的形式存在，可以将其解压，一般来说，直接使用框架内置的 MNIST 则不必执行这一步，深度学习框架会帮我们下载好这些数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集\n",
    "\n",
    "我们首先以 PyTorch 框架为基础，向大家展示使用 MNIST 数据集训练神经网络模型的流程。\n",
    "\n",
    "由于 `torchvision.datasets.MNIST` 内置了 MNIST 数据集的读取接口，我们会直接调用：\n",
    "\n",
    "```Python\n",
    "from torchvision import datasets\n",
    "datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
    "```\n",
    "\n",
    "其中：\n",
    "- root：指的是下载路径，这里人工指定为你所需要的路径。\n",
    "- train：True就是训练集，False就是测试集\n",
    "- download：True指的是如果没有数据集则下载，如果有就不下载。\n",
    "- transform：指的是数据变换增强，比如翻转，拉伸等等。在这一步我们**先检查数据**，不使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST_pytorch/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST_pytorch/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST_pytorch/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST_pytorch/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST_pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████▎| 9805824/9912422 [00:25<00:00, 891507.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_pytorch/MNIST\\raw\\train-images-idx3-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "32768it [00:00, 50018.09it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_pytorch/MNIST\\raw\\train-labels-idx1-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|▋                                                                      | 16384/1648877 [00:00<00:25, 65231.61it/s]\n",
      "  3%|██                                                                     | 49152/1648877 [00:00<00:20, 78474.07it/s]\n",
      "  6%|████▏                                                                  | 98304/1648877 [00:01<00:15, 97472.22it/s]\n",
      " 13%|████████▉                                                            | 212992/1648877 [00:01<00:11, 128793.87it/s]\n",
      " 20%|█████████████▋                                                       | 327680/1648877 [00:01<00:07, 166401.97it/s]\n",
      " 27%|██████████████████▊                                                  | 450560/1648877 [00:01<00:05, 209363.85it/s]\n",
      " 30%|████████████████████▌                                                | 491520/1648877 [00:02<00:06, 191986.66it/s]\n",
      " 39%|███████████████████████████                                          | 647168/1648877 [00:02<00:04, 250253.51it/s]\n",
      " 45%|██████████████████████████████▊                                      | 737280/1648877 [00:02<00:02, 305470.97it/s]\n",
      " 48%|█████████████████████████████████▎                                   | 794624/1648877 [00:02<00:02, 336128.35it/s]\n",
      " 52%|███████████████████████████████████▋                                 | 851968/1648877 [00:02<00:02, 336653.06it/s]\n",
      " 57%|███████████████████████████████████████▍                             | 942080/1648877 [00:02<00:01, 357210.11it/s]\n",
      " 64%|███████████████████████████████████████████▏                        | 1048576/1648877 [00:03<00:01, 387096.08it/s]\n",
      " 70%|███████████████████████████████████████████████▋                    | 1155072/1648877 [00:03<00:01, 453623.47it/s]\n",
      " 74%|██████████████████████████████████████████████████                  | 1212416/1648877 [00:03<00:00, 459848.79it/s]\n",
      " 78%|████████████████████████████████████████████████████▋               | 1277952/1648877 [00:03<00:00, 423345.32it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▍          | 1392640/1648877 [00:03<00:00, 499211.79it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▏       | 1458176/1648877 [00:03<00:00, 497693.78it/s]\n",
      " 92%|██████████████████████████████████████████████████████████████▌     | 1515520/1648877 [00:04<00:00, 430108.59it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████▏| 1630208/1648877 [00:04<00:00, 523052.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_pytorch/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "8192it [00:00, 18316.70it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_pytorch/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../datasets/MNIST_pytorch/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9920512it [00:40, 891507.80it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=None)\n",
    "else:\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完毕后，检查一下数据集有多大，并且看看数据集训练集的第一条信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x19BA2EB88C8>, 5)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset[0])\n",
    "print(type(mnist_trainset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，数据集的训练集共有60000张图片，而测试集共有10000张图片。\n",
    "\n",
    "图片的类型都是 PIL.Image，以 tuple 形式保存。\n",
    "\n",
    "现在我们要读取测试集第一张图片 `mnist_testset[0]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的标签是：  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_zero, test_target_zero = mnist_testset[0]\n",
    "plt.imshow(test_image_zero, cmap ='gray')  # 灰度图像\n",
    "print(\"该图片的标签是： \",test_target_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知道，MNIST 数据集是灰度图像，而绘制出的结果也确实如此。上图展示的图片，很容易看出是一个手写的阿拉伯数字 “7”，分辨率是 $28\\times28$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "在下载完毕 MNIST 数据集以后，我们要如何将数据放入神经网络中呢？\n",
    "\n",
    "之前我们讲过，由于计算机的内存有限，在面对大规模数据集时不能一次性将所有数据放入模型进行训练，所以我们采用 mini-batch 的形式读取并训练数据集。\n",
    "\n",
    "所以现在我们的任务是创建一个**数据迭代器（Data Iterator）**，这个迭代器的作用是每次从数据集中挑选一定量的子集（mini-batch）放入神经网络进行训练，完成这一个 batch 的训练后再挑选另一个子集的数据继续训练。\n",
    "\n",
    "一个子集的大小叫做 “**batch size**”，它是一个超参数，具体的值需要根据显存（内存）大小来设置。\n",
    "\n",
    "### 数据迭代器 DataLoader\n",
    "\n",
    "PyTorch 已经为我们提供了这么一个数据迭代器类型，叫做`torch.utils.data.DataLoader`。有了这个 `DataLoader`，我们可以非常方便地把我们的数据以 mini-batch 的形式读取进来。\n",
    "\n",
    "首先我们来看看 [DataLoader] 的结构：\n",
    "\n",
    "```python\n",
    "torch.utils.data.DataLoader(dataset, \n",
    "                            batch_size=1, \n",
    "                            shuffle=False, \n",
    "                            sampler=None, \n",
    "                            batch_sampler=None, \n",
    "                            num_workers=0, \n",
    "                            collate_fn=None, \n",
    "                            pin_memory=False, \n",
    "                            drop_last=False, \n",
    "                            timeout=0, \n",
    "                            worker_init_fn=None, \n",
    "                            multiprocessing_context=None)\n",
    "```\n",
    "\n",
    "看起来 `Dataloader` 内的参数非常多，但是在这里我们只关注几个最重要的参数，其他参数在以后需要使用的时候再讲解。\n",
    "\n",
    "- **dataset** ([*Dataset*](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset)) – 我们将要读取的数据集。\n",
    "\n",
    "- **batch_size** (*int, optional*) – 每一个batch中要读取多少个数据 (default: 1)。\n",
    "\n",
    "- **shuffle** (*bool, optional*) – 在默认情况下，是按顺序进行采样的。如果要在每个 epoch 中随机打乱采样顺序，设置为`True` (default: False)。\n",
    "\n",
    "### Tensor 格式转换\n",
    "\n",
    "在 `torchvision.transforms` 模块中提供了非常多的图像变换、图像增强方法，包括亮度增强、拉伸缩放、旋转翻转等等。关于图像增强的方法，我们在此暂不涉及，这里我们仅仅采用 `transforms` 中的 `to_tensor()` 函数将 PIL 图像转变为 tensor 形式。\n",
    "\n",
    "`to_tensor()` 函数将每一张 $28\\times28$ 像素的手写数字图片中的灰度信息变为 tensor 的形式。 \n",
    "\n",
    "> **Tensor**，中文名叫**张量**，是包含单一数据类型的多维矩阵，和 NumPy 中的 `np.array()` 非常类似。在 TensorFlow 和 PyTorch 中主要采用的数据结构就是tensor。具体的，PyTorch Tensor 在 CPU 和 GPU 上各有9种数据类型，可以参见[TORCH.TENSOR](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)。\n",
    "\n",
    "我们尝试将测试集第一张图片 “7” 转换为 tensor 的形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
      "          0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
      "          0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "          0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
      "          0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
      "          0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
      "          0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
      "          0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
      "          0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
      "          0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
      "          0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
      "          0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在知道 `to_tensor()` 的工作原理之后，我们将数据转换为 tensor 并转入迭代器的步骤如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST_pytorch/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST_pytorch/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST_pytorch/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST_pytorch/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST_pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经下载。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:23, 523052.35it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "# PIL to Tensor\n",
    "data_tf = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 准备数据集\n",
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    print(\"已经下载。\")\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=data_tf)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=data_tf)\n",
    "else:\n",
    "    print(\"需要下载。\")\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) \n",
    "\n",
    "# 放入迭代器\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好了训练集和测试集的迭代器以后，我们就做好了数据的准备工作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络结构\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们当时搭建了一个非常简单的三层神经网络，每一层神经元只有仅仅两三个。\n",
    "\n",
    "神经元的数量少，有利于我们推导前向传播公式，理解神经网络结构，但要解决真实问题却不太够。因此今天我们将要搭建一个神经元更多一些的三层神经网络，如下图：\n",
    "\n",
    "![三层网络](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/back_up_images/%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%A4%9A%E4%B8%AA%E7%A5%9E%E7%BB%8F%E5%85%83.png?raw=true)\n",
    "\n",
    "可以看到，在全连接层中，随着神经元的增加，神经网络变得更加复杂了起来。但是层数依旧是三层。\n",
    "\n",
    "> 需要注意的是，在输出层我们采用了 `softmax` 函数，以输出图像每个数字分类的概率。\n",
    "\n",
    "现在我们按照上图中的说明，正式开始搭建神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"定义神经网络Net\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化各个层\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播\"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查系统状态\n",
    "\n",
    "检查 PyTorch 版本和 GPU 状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.3.1\n",
      "Is CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch 版本： {torch.__version__}\")\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(\"GPU numbers: \", n_gpu)\n",
    "    print(\"device_name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器的设置\n",
    "\n",
    "首先，我们需要将定义好的神经网络模型放入 `device` 中，这个 `device` 之前已经由我们编程选择好了，如果电脑的GPU可用，则会选择放入GPU，如果不可用则会选择放入CPU。\n",
    "\n",
    "其次我们需要给神经网络选择一个优化器。之前我们学习过，普通的神经网络会最常见的的优化方法就是随机梯度下降法（Stochastic Gradient Descent，SGD），从而减小损失函数。因此这里我们也使用随机梯度下降法来作为我们的优化器。后续我们会讨论其他类型的优化器。\n",
    "\n",
    "> 实际上还有很多优化器，SGD 只是最常见的优化器之一。可以参见[TORCH.OPTIM](https://pytorch.org/docs/stable/optim.html?highlight=sgd#module-torch.optim)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(),    # 模型参数\n",
    "                      lr=0.03,               # 学习率\n",
    "                      momentum=0)            # 动量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练函数\n",
    "\n",
    "在设置完毕优化器之后，我们开始定义整个模型需要如何训练。\n",
    "\n",
    "#### model.train()\n",
    "\n",
    "需要了解的是，PyTorch 的模型在训练之前需要使用命令\n",
    "\n",
    "```python\n",
    "model.train()\n",
    "```\n",
    "\n",
    "来对模型开启训练模式。\n",
    "\n",
    "#### 将 mini-batch 数据放入device\n",
    "\n",
    "之前我们使用 `to(device)` 命令将模型放入了 device 中（这里 device 是 CPU）。我们还需要将训练数据和标签也放入 device 中。这样一来，模型和数据都在 device 中，我们的模型才能正常读取数据并训练。\n",
    "\n",
    "由于之前我们将数据和标签放入了一个迭代器中，所以要分批获取这些数据并放入 device 中。故这里需要使用一个 `for` 循环，按 batch_size 处理我们的数据。\n",
    "\n",
    "> **重要**：关于数据维度的变化：`data = data.view(data.shape[0], -1)` 的操作，将原本是 $28\\times28$ 的图像拉平（flatten）到了 $768$。因为在我们定义的神经网络中，第一层接受的是一个 $768$ 维的输入，而 data 原本的维度是 $1000\\times1\\times28\\times28$。\n",
    "\n",
    "#### 梯度归零\n",
    "\n",
    "在 PyTorch 训练过程中，每训练一个 batch 的数据，我们的优化器需要使用 `optimizer.zero_grad()` 进行梯度归零。回顾之前学习的梯度下降法，每次学习的梯度只对本 batch 数据负责，到了下一个 batch 我们又需要将梯度归零，然后重新计算梯度。\n",
    "\n",
    "如果不执行梯度归零，那么每个 batch 的梯度会累加起来，导致结果出错。\n",
    "\n",
    "#### 反向传播\n",
    "\n",
    "接下来我们定义损失函数。这里我们采用的是 [NLLLoss](https://pytorch.org/docs/stable/nn.functional.html?highlight=nll_loss#torch.nn.functional.nll_loss)，即 “Negative Log Likelihood loss”。它和之前的交叉熵损失函数（Cross Entropy Loss）是一回事。在 PyTorch 中，[torch.nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss) 结合了 `nn.LogSoftmax()` 和 `nn.NLLLoss()`。\n",
    "\n",
    "换句话说，`torch.nn.CrossEntropyLoss()` 会额外计算一次 softmax ，由于我们在网络的末尾定义了 log_softmax() 输出，所以只需要 `nn.NLLLoss()` 就足够了。\n",
    "\n",
    "最后我们要记得使用 `optimizer.step()` 更新模型的参数。[torch.optim.Optimizer.step](https://pytorch.org/docs/stable/optim.html?highlight=optimizer%20step#torch.optim.Optimizer.step) 表示单步（一个 batch 的数据）更新模型的参数。\n",
    "\n",
    "#### 打印 loss 值\n",
    "\n",
    "有时候我们需要在训练过程中看看模型的 loss 是否在下降，所以采用打印 loss 的方式来观察，简单有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(data.shape[0], -1)  # 从 28*28 转换为 768\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset)}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325443\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.281106\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.233303\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.194489\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.150049\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.098475\n",
      "\n",
      "Test set: Average loss: 2.0268757080078124, Accuracy: 5830/10000 (58.3%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.032766\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.950281\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.870401\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.758174\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.668907\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.564158\n",
      "\n",
      "Test set: Average loss: 1.457149072265625, Accuracy: 6574/10000 (65.74%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.479914\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.363023\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.276601\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.196392\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.172119\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.059146\n",
      "\n",
      "Test set: Average loss: 0.9903579223632812, Accuracy: 7672/10000 (76.72%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.017578\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.976169\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.905425\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.872319\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.832379\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.820661\n",
      "\n",
      "Test set: Average loss: 0.7470351684570312, Accuracy: 8174/10000 (81.74%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.778958\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.717441\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.679638\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.689593\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.643914\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.659067\n",
      "\n",
      "Test set: Average loss: 0.6162839538574219, Accuracy: 8426/10000 (84.26%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.588918\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.600300\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.612312\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.576355\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.551217\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.558841\n",
      "\n",
      "Test set: Average loss: 0.5392284545898437, Accuracy: 8580/10000 (85.8%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.584446\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.569575\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.556124\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.532165\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.566590\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.487007\n",
      "\n",
      "Test set: Average loss: 0.48835273742675783, Accuracy: 8685/10000 (86.85%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.502948\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.502630\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.504559\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.469145\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.524361\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.469404\n",
      "\n",
      "Test set: Average loss: 0.4528595458984375, Accuracy: 8767/10000 (87.67%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.479304\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.476471\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.487806\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.452709\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.444401\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.430119\n",
      "\n",
      "Test set: Average loss: 0.4272017639160156, Accuracy: 8817/10000 (88.17%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "#if (args.save_model):\n",
    "#    torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型\n",
    "\n",
    "在完成了模型的训练之后，我们需要将模型保存下来，以便后续使用。\n",
    "\n",
    "参考代码：[SAVING AND LOADING MODELS](https://pytorch.org/tutorials/beginner/saving_loading_models.html?highlight=save)\n",
    "\n",
    "### 状态字典 state_dict\n",
    "\n",
    "在 PyTorch 中，`torch.nn.Module` 模型的可学习参数（权重和偏差）包含在模型的参数（parameters）中，可以通过 `model.parameters()` 访问。 \n",
    "\n",
    "*state_dict* 是一个 Python 的字典（dictionary ）对象，它将每个 layer 映射到字典里面。\n",
    "\n",
    "由于 *state_dict* 是 Python字典，所以可以轻松保存、更新、更改以及还原模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([100, 784])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([50, 100])\n",
      "fc2.bias \t torch.Size([50])\n",
      "fc3.weight \t torch.Size([10, 50])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.03, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [1768020598200, 1768020596600, 1768020810552, 1768020811112, 1768020809272, 1768020807832]}]\n"
     ]
    }
   ],
   "source": [
    "# 打印模型的 state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "# 打印优化器的 state_dict\n",
    "print(\"\\nOptimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存和读取模型\n",
    "\n",
    "我们推荐使用保存、读取 `state_dict` 的形式来存取模型。\n",
    "\n",
    "方法如下：\n",
    "\n",
    "**Save**：\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "```\n",
    "\n",
    "**Load**\n",
    "\n",
    "```python\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "在保存模型，以便以后复用的时候，我们实际上只需要保存经过训练的模型的学习参数（$W$ 以及 $b$），所以使用 `torch.save()` 函数保存模型的 *state_dict* 会非常方便灵活。\n",
    "\n",
    "> 记住，读取模型以后需要调用 `model.eval()` 进入评估模式，否则可能出现不一样的预测结结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./model_save_3.04/model_save_3.04\"\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，由于我们之前采用了 \n",
    "\n",
    "```python\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "对我们的设备进行判断，如果 GPU 可用则在 GPU 上训练，否则在 CPU 上训练，因此这里我们也需要配套处理读取后模型的位置。参考：[Saving & Loading Model Across Devices](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-across-devices)\n",
    "\n",
    "> 为了区分，我们将读取后的模型叫做 *model_2* 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_2 = Net()\n",
    "model_2.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model_2.to(device)\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来测试一下读取后的模型效果。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.42720166625976563, Accuracy: 8817/10000 (88.17%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model_2, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - 训练MNIST\n",
    "\n",
    ">Keras 是一个更高级别的框架，将常用的深度学习层和运算封装进干净、乐高大小的构造块，使数据科学家不用再考虑深度学习的复杂度。\n",
    ">\n",
    ">PyTorch 提供一个相对较低级别的实验环境，使用户可以更加自由地写自定义层、查看数值优化任务。\n",
    ">\n",
    ">链接：https://zhuanlan.zhihu.com/p/38710857\n",
    "\n",
    "我鼓励大家在 Keras 和 PyTorch 中都尝试下简单的深度学习模型。这里我同样给出 MNIST 在 Keras 上面的训练过程代码，参考了 [TensorFlow 2 quickstart for beginners](https://tensorflow.google.cn/tutorials/quickstart/beginner)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集\n",
    "\n",
    "[MNIST 数据集](http://yann.lecun.com/exdb/mnist/)的读取接口已经内置在 TensorFlow 中，如果数据文件不存在，会自动下载。\n",
    "\n",
    "我们读取数据集，然后将数据集从整数转换为浮点数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件是否存在：True\n"
     ]
    }
   ],
   "source": [
    "file = \"../datasets/MNIST_tf2.0/mnist.npz\"\n",
    "print(f\"文件是否存在：{os.path.exists(file)}\")\n",
    "file_path = os.path.abspath(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "if os.path.exists(file):\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path=file_path)\n",
    "else:\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建模型\n",
    "\n",
    "使用 [tf.keras.Sequential](https://tensorflow.google.cn/api_docs/python/tf/keras/Sequential?version=stable) 搭建模型。\n",
    "\n",
    "然后选择合适的优化器（optimizer ）和损失函数（loss function）。\n",
    "\n",
    "具体结构和上文 PyTorch 搭建的模型一致：\n",
    "\n",
    "```\n",
    "Model：\n",
    "Net(\n",
    "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
    "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
    "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmodel = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "tfmodel.compile(optimizer='SGD',                         # SGD优化器\n",
    "                loss='sparse_categorical_crossentropy',  # 交叉熵损失\n",
    "                metrics=['accuracy'])                    # 评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和预测\n",
    "\n",
    "首先我们使用 `scheduler` 指定学习率，然后放入 `model.fit` 中。\n",
    "\n",
    "> `scheduler` 可以起到在不同的 epoch 中控制学习率变化的作用，有时候需要 warm up，或者在最后几个 epoch 收缩学习率的时候会用到。参见[tf.keras.callbacks.LearningRateScheduler](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/LearningRateScheduler?hl=en&version=stable)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 - 2s - loss: 0.4325 - accuracy: 0.8767\n",
      "Epoch 2/10\n",
      "60000/60000 - 2s - loss: 0.2031 - accuracy: 0.9412\n",
      "Epoch 3/10\n",
      "60000/60000 - 2s - loss: 0.1515 - accuracy: 0.9562\n",
      "Epoch 4/10\n",
      "60000/60000 - 2s - loss: 0.1212 - accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "60000/60000 - 2s - loss: 0.1009 - accuracy: 0.9704\n",
      "Epoch 6/10\n",
      "60000/60000 - 2s - loss: 0.0859 - accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "60000/60000 - 2s - loss: 0.0744 - accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "60000/60000 - 2s - loss: 0.0649 - accuracy: 0.9815\n",
      "Epoch 9/10\n",
      "60000/60000 - 2s - loss: 0.0580 - accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "60000/60000 - 2s - loss: 0.0510 - accuracy: 0.9853\n",
      "10000/1 - 0s - loss: 0.0389 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07713340574782342, 0.9751]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "tfmodel.fit(x_train, y_train, epochs=10, callbacks=[callback], verbose=2)\n",
    "\n",
    "tfmodel.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是我们得到结果。可以看出 Keras 和 PyTorch 相比，似乎准确率更高一些。\n",
    "\n",
    "但是，请注意，这产生这些区别的**原因很多**，可能是 Keras 优化器内部参数设置不一致，并非框架本身的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存与读取\n",
    "\n",
    "接下来是 Keras 的模型保存，需要指定好保存的路径。\n",
    "\n",
    "#### 保存\n",
    "\n",
    "保存方法如下，参考文档 [tf.keras.models.save_model](https://tensorflow.google.cn/api_docs/python/tf/keras/models/save_model?hl=en&version=stable)。\n",
    "\n",
    "```python\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_save_3.04/model_save_3.04_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "    tfmodel,\n",
    "    filepath=\"./model_save_3.04/model_save_3.04_tf\",\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取\n",
    "\n",
    "模型的读取方法如下，参考文档 [tf.keras.models.load_model](https://tensorflow.google.cn/api_docs/python/tf/keras/models/load_model?hl=en&version=stable)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmodel_2 = tf.keras.models.load_model(\n",
    "                                        filepath=\"./model_save_3.04/model_save_3.04_tf\",\n",
    "                                        custom_objects=None,\n",
    "                                        compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 84,060\n",
      "Trainable params: 84,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tfmodel_2.summary()  # 查看模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
