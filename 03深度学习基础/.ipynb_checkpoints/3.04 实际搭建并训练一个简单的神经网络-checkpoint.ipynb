{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际搭建并训练一个简单的神经网络\n",
    "\n",
    "作者：杨岱川\n",
    "\n",
    "时间：2019年12月\n",
    "\n",
    "github：https://github.com/DrDavidS/basic_Machine_Learning\n",
    "\n",
    "开源协议：[MIT](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/LICENSE)\n",
    "\n",
    "参考文献：\n",
    "\n",
    "- 《深度学习入门》，作者：斋藤康毅；\n",
    "- 《深度学习》，作者：Ian Goodfellow 、Yoshua Bengio、Aaron Courville。\n",
    "- [Keras overview](https://tensorflow.google.cn/guide/keras/overview)\n",
    "- [PYTORCH TUTORIALS](https://pytorch.org/tutorials/)\n",
    "\n",
    "### 学习回顾\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们学习了如何搭建一个三层的全连接神经网络，并且实现了它的前向传播过程。\n",
    "\n",
    "在 [3.02 神经网络的训练](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.02%20神经网络的训练.ipynb)中，我们主要学习了如何使用数值微分的方法计算神经网络的梯度，并通过随机梯度下降法去优化神经网络的参数。\n",
    "\n",
    "在 [3.03 误差反向传播法](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.03%20误差反向传播法.ipynb)中，我们主要学习了计算图的原理，以及如何使用计算图的**反向传播**高效地计算导数，并且实现了加法乘法以及部分简单函数的反向传播推导。\n",
    "\n",
    "可以说到目前为止，全连接神经网络的最重要的几个数学原理我们已经有部分概念了。可能你记不得具体某个公式怎么写，某个函数怎么编程，这些都没有关系。关键在于，你知道这些名词的**概念**和用途，并且你知道有朝一日要在实际工作和科研中运用的时候去哪里**查询**具体用法。\n",
    "\n",
    "熟练来自于长期的积累，我们现在只走出了第一步。\n",
    "\n",
    "### 学习目标\n",
    "\n",
    "在上述三份 notebook 中，我们基本都是用 Python 亲手实现了前向传播和反向传播的各个过程和结构。但是在实际科研和工作中，我们并没有如此多的时间或精力去 “手写” 这么一份网络结构代码。\n",
    "\n",
    "更常见的情况是，我们会使用各种成熟的深度学习框架系统来完成对网络结构的搭建，比如大家熟悉的 TensorFlow2.0 或者 PyTorch 。\n",
    "\n",
    "对于这两个框架我就不多介绍了，我们在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中已经有过初步接触。不过那时候我们只是实现了一个最简单的三层全连接神经网络，然后实验了一下前向传播的计算过程，并没有涉及训练和优化等更多内容。\n",
    "\n",
    "在学习了 “随机梯度下降法” 和 “误差反向传播” 法地理论基础以后，我们终于可以正式地在深度学习框架中运用这些方法技巧，完成训练。\n",
    "\n",
    "本章节的目标就是：**运用深度学习框架搭建一个神经网络模型，实现对简单数据集的训练和预测。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "\n",
    "### MNIST 数据集\n",
    "\n",
    "首先向大家介绍 [MNIST 手写数字数据集](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 手写数字数据集在机器学习界可以说是无人不知无人不晓。美国国家标准与技术研究院（National Institute of Standards and Technology，NIST），而 MNIST 就是 “Modified National Institute of Standards and Technology” 的缩写。\n",
    "\n",
    "此数据集自1999年发布以来，已经成为了图像分类领域的基础数据集。随着技术不断进步，各种新分类方法不断出现，MNIST 数据集成为了检验这些方法的常用数据集之一。\n",
    "\n",
    "MINIST实验包含了四个文件，其中`train-images-idx3-ubyte`是 60000 个图片样本，`train-labels-idx1-ubyte`是这 60000 个图片对应的数字标签，`t10k-images-idx3-ubyte` 是用于测试的样本，`t10k-labels-idx1-ubyte` 是测试样本对应的数字标签。\n",
    "\n",
    "这份数据集采集自美国人口调查局的员工和高中生，内容为 0-9 一共十个数字的手写体。我们的任务就是从成千上万的数字中训练并构建一个模型，能识别这些图像中的手写数字。\n",
    "\n",
    "MNIST的图像数据是28像素×28像素的灰度图像（1通道），各个像素的取值在0到255之间。每个图像都相应地标有“1”、“2”、“3”等标签。\n",
    "\n",
    "很多框架中已经内置了 MNIST 数据集，调用十分方便：\n",
    "\n",
    "- TensorFlow：[tfds.image.mnist.MNIST](https://tensorflow.google.cn/datasets/catalog/mnist?hl=en)\n",
    "- PyTorch：[torchvision.datasets.MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST)\n",
    "\n",
    "\n",
    "### 下载 MNIST 数据集\n",
    "\n",
    "在 MNIST 数据集官网可以直接下载数据集：http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "共有四个文件，如下：\n",
    "\n",
    "```\n",
    "- train-images-idx3-ubyte.gz:  training set images (9912422 bytes) \n",
    "- train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) \n",
    "- t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) \n",
    "- t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n",
    "```\n",
    "\n",
    "四个文件夹以压缩文件的形式存在，可以将其解压，一般来说，直接使用框架内置的 MNIST 则不必执行这一步，深度学习框架会帮我们下载好这些数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集\n",
    "\n",
    "我们首先以 PyTorch 框架为基础，向大家展示使用 MNIST 数据集训练神经网络模型的流程。\n",
    "\n",
    "由于 `torchvision.datasets.MNIST` 内置了 MNIST 数据集的读取接口，我们会直接调用：\n",
    "\n",
    "```Python\n",
    "from torchvision import datasets\n",
    "datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
    "```\n",
    "\n",
    "其中：\n",
    "- root：指的是下载路径，这里人工指定为你所需要的路径。\n",
    "- train：True就是训练集，False就是测试集\n",
    "- download：True指的是如果没有数据集则下载，如果有就不下载。\n",
    "- transform：指的是数据变换增强，比如翻转，拉伸等等。在这一步我们**先检查数据**，不使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../datasets/MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:05, 1807895.93it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz to ../datasets/MNIST/MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../datasets/MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:05, 5777.37it/s]                                                                                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz to ../datasets/MNIST/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1017296.36it/s]                                                                                      \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../datasets/MNIST/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:04, 1682.64it/s]                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=data_tf)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=data_tf)\n",
    "else:\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完毕后，检查一下数据集有多大，并且看看数据集训练集的第一条信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x258F29B3588>, 5)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset[0])\n",
    "print(type(mnist_trainset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，数据集的训练集共有60000张图片，而测试集共有10000张图片。\n",
    "\n",
    "图片的类型都是 PIL.Image，以 tuple 形式保存。\n",
    "\n",
    "现在我们要读取测试集第一张图片 `mnist_testset[0]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的标签是：  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_zero, test_target_zero = mnist_testset[0]\n",
    "plt.imshow(test_image_zero, cmap ='gray')  # 灰度图像\n",
    "print(\"该图片的标签是： \",test_target_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知道，MNIST 数据集是灰度图像，而绘制出的结果也确实如此。上图展示的图片，很容易看出是一个手写的阿拉伯数字 “7”，分辨率是 $28\\times28$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "在下载完毕 MNIST 数据集以后，我们要如何将数据放入神经网络中呢？\n",
    "\n",
    "之前我们讲过，由于计算机的内存有限，在面对大规模数据集时不能一次性将所有数据放入模型进行训练，所以我们采用 mini-batch 的形式读取并训练数据集。\n",
    "\n",
    "所以现在我们的任务是创建一个**数据迭代器（Data Iterator）**，这个迭代器的作用是每次从数据集中挑选一定量的子集（mini-batch）放入神经网络进行训练，完成这一个 batch 的训练后再挑选另一个子集的数据继续训练。\n",
    "\n",
    "一个子集的大小叫做 “**batch size**”，它是一个超参数，具体的值需要根据显存（内存）大小来设置。\n",
    "\n",
    "### 数据迭代器 DataLoader\n",
    "\n",
    "PyTorch 已经为我们提供了这么一个数据迭代器类型，叫做`torch.utils.data.DataLoader`。有了这个 `DataLoader`，我们可以非常方便地把我们的数据以 mini-batch 的形式读取进来。\n",
    "\n",
    "首先我们来看看 [DataLoader] 的结构：\n",
    "\n",
    "```python\n",
    "torch.utils.data.DataLoader(dataset, \n",
    "                            batch_size=1, \n",
    "                            shuffle=False, \n",
    "                            sampler=None, \n",
    "                            batch_sampler=None, \n",
    "                            num_workers=0, \n",
    "                            collate_fn=None, \n",
    "                            pin_memory=False, \n",
    "                            drop_last=False, \n",
    "                            timeout=0, \n",
    "                            worker_init_fn=None, \n",
    "                            multiprocessing_context=None)\n",
    "```\n",
    "\n",
    "看起来 `Dataloader` 内的参数非常多，但是在这里我们只关注几个最重要的参数，其他参数在以后需要使用的时候再讲解。\n",
    "\n",
    "- **dataset** ([*Dataset*](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset)) – 我们将要读取的数据集。\n",
    "\n",
    "- **batch_size** (*int, optional*) – 每一个batch中要读取多少个数据 (default: 1)。\n",
    "\n",
    "- **shuffle** (*bool, optional*) – 在默认情况下，是按顺序进行采样的。如果要在每个 epoch 中随机打乱采样顺序，设置为`True` (default: False)。\n",
    "\n",
    "### Tensor 格式转换\n",
    "\n",
    "在 `torchvision.transforms` 模块中提供了非常多的图像变换、图像增强方法，包括亮度增强、拉伸缩放、旋转翻转等等。关于图像增强的方法，我们在此暂不涉及，这里我们仅仅采用 `transforms` 中的 `to_tensor()` 函数将 PIL 图像转变为 tensor 形式。\n",
    "\n",
    "`to_tensor()` 函数将每一张 $28\\times28$ 像素的手写数字图片中的灰度信息变为 tensor 的形式。 \n",
    "\n",
    "> **Tensor**，中文名叫**张量**，是包含单一数据类型的多维矩阵，和 NumPy 中的 `np.array()` 非常类似。在 TensorFlow 和 PyTorch 中主要采用的数据结构就是tensor。具体的，PyTorch Tensor 在 CPU 和 GPU 上各有9种数据类型，可以参见[TORCH.TENSOR](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)。\n",
    "\n",
    "我们尝试将测试集第一张图片 “7” 转换为 tensor 的形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
      "          0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
      "          0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "          0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
      "          0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
      "          0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
      "          0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
      "          0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
      "          0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
      "          0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
      "          0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
      "          0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在知道 `to_tensor()` 的工作原理之后，我们将数据转换为 tensor 并转入迭代器的步骤如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL to Tensor\n",
    "data_tf = transforms.Compose(transforms.ToTensor())\n",
    "\n",
    "# 准备数据集\n",
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=data_tf)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=data_tf)\n",
    "else:\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) \n",
    "\n",
    "# 放入迭代器\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好了训练集和测试集的迭代器以后，我们就做好了数据的准备工作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络结构\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们当时搭建了一个非常简单的三层神经网络，每一层神经元只有仅仅两三个。\n",
    "\n",
    "神经元的数量少，有利于我们推导前向传播公式，理解神经网络结构，但要解决真实问题却不太够。因此今天我们将要搭建一个神经元更多一些的三层神经网络，如下图：\n",
    "\n",
    "![三层网络](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/back_up_images/%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%A4%9A%E4%B8%AA%E7%A5%9E%E7%BB%8F%E5%85%83.png?raw=true)\n",
    "\n",
    "可以看到，在全连接层中，随着神经元的增加，神经网络变得更加复杂了起来。但是层数依旧是三层。\n",
    "\n",
    "> 需要注意的是，在输出层我们采用了 `softmax` 函数，以输出图像每个数字分类的概率。\n",
    "\n",
    "现在我们按照上图中的说明，正式开始搭建神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"定义神经网络Net\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化各个层\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播\"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查系统状态\n",
    "\n",
    "检查 PyTorch 版本和 GPU 状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.3.1\n",
      "Is CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch 版本： {torch.__version__}\")\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"GPU numbers: \", n_gpu)\n",
    "    print(\"device_name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
