{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际搭建并训练一个简单的神经网络\n",
    "\n",
    "作者：杨岱川\n",
    "\n",
    "时间：2019年12月\n",
    "\n",
    "github：https://github.com/DrDavidS/basic_Machine_Learning\n",
    "\n",
    "开源协议：[MIT](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/LICENSE)\n",
    "\n",
    "参考文献：\n",
    "\n",
    "- 《深度学习入门》，作者：斋藤康毅；\n",
    "- 《深度学习》，作者：Ian Goodfellow 、Yoshua Bengio、Aaron Courville。\n",
    "- [Keras overview](https://tensorflow.google.cn/guide/keras/overview)\n",
    "- [PYTORCH TUTORIALS](https://pytorch.org/tutorials/)\n",
    "\n",
    "### 学习回顾\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们学习了如何搭建一个三层的全连接神经网络，并且实现了它的前向传播过程。\n",
    "\n",
    "在 [3.02 神经网络的训练](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.02%20神经网络的训练.ipynb)中，我们主要学习了如何使用数值微分的方法计算神经网络的梯度，并通过随机梯度下降法去优化神经网络的参数。\n",
    "\n",
    "在 [3.03 误差反向传播法](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.03%20误差反向传播法.ipynb)中，我们主要学习了计算图的原理，以及如何使用计算图的**反向传播**高效地计算导数，并且实现了加法乘法以及部分简单函数的反向传播推导。\n",
    "\n",
    "可以说到目前为止，全连接神经网络的最重要的几个数学原理我们已经有部分概念了。可能你记不得具体某个公式怎么写，某个函数怎么编程，这些都没有关系。关键在于，你知道这些名词的**概念**和用途，并且你知道有朝一日要在实际工作和科研中运用的时候去哪里**查询**具体用法。\n",
    "\n",
    "熟练来自于长期的积累，我们现在只走出了第一步。\n",
    "\n",
    "### 学习目标\n",
    "\n",
    "在上述三份 notebook 中，我们基本都是用 Python 亲手实现了前向传播和反向传播的各个过程和结构。但是在实际科研和工作中，我们并没有如此多的时间或精力去 “手写” 这么一份网络结构代码。\n",
    "\n",
    "更常见的情况是，我们会使用各种成熟的深度学习框架系统来完成对网络结构的搭建，比如大家熟悉的 TensorFlow2.0 或者 PyTorch 。\n",
    "\n",
    "对于这两个框架我就不多介绍了，我们在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中已经有过初步接触。不过那时候我们只是实现了一个最简单的三层全连接神经网络，然后实验了一下前向传播的计算过程，并没有涉及训练和优化等更多内容。\n",
    "\n",
    "在学习了 “随机梯度下降法” 和 “误差反向传播” 法地理论基础以后，我们终于可以正式地在深度学习框架中运用这些方法技巧，完成训练。\n",
    "\n",
    "本章节的目标就是：**运用深度学习框架搭建一个神经网络模型，实现对简单数据集的训练和预测。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "\n",
    "### MNIST 数据集\n",
    "\n",
    "首先向大家介绍 [MNIST 手写数字数据集](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 手写数字数据集在机器学习界可以说是无人不知无人不晓。美国国家标准与技术研究院（National Institute of Standards and Technology，NIST），而 MNIST 就是 “Modified National Institute of Standards and Technology” 的缩写。\n",
    "\n",
    "此数据集自1999年发布以来，已经成为了图像分类领域的基础数据集。随着技术不断进步，各种新分类方法不断出现，MNIST 数据集成为了检验这些方法的常用数据集之一。\n",
    "\n",
    "MINIST实验包含了四个文件，其中`train-images-idx3-ubyte`是 60000 个图片样本，`train-labels-idx1-ubyte`是这 60000 个图片对应的数字标签，`t10k-images-idx3-ubyte` 是用于测试的样本，`t10k-labels-idx1-ubyte` 是测试样本对应的数字标签。\n",
    "\n",
    "这份数据集采集自美国人口调查局的员工和高中生，内容为 0-9 一共十个数字的手写体。我们的任务就是从成千上万的数字中训练并构建一个模型，能识别这些图像中的手写数字。\n",
    "\n",
    "MNIST的图像数据是28像素×28像素的灰度图像（1通道），各个像素的取值在0到255之间。每个图像都相应地标有“1”、“2”、“3”等标签。\n",
    "\n",
    "很多框架中已经内置了 MNIST 数据集，调用十分方便：\n",
    "\n",
    "- TensorFlow：[tfds.image.mnist.MNIST](https://tensorflow.google.cn/datasets/catalog/mnist?hl=en)\n",
    "- PyTorch：[torchvision.datasets.MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST)\n",
    "\n",
    "\n",
    "### 下载 MNIST 数据集\n",
    "\n",
    "在 MNIST 数据集官网可以直接下载数据集：http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "共有四个文件，如下：\n",
    "\n",
    "```\n",
    "- train-images-idx3-ubyte.gz:  training set images (9912422 bytes) \n",
    "- train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) \n",
    "- t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) \n",
    "- t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n",
    "```\n",
    "\n",
    "四个文件夹以压缩文件的形式存在，可以将其解压，一般来说，直接使用框架内置的 MNIST 则不必执行这一步，深度学习框架会帮我们下载好这些数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集\n",
    "\n",
    "我们首先以 PyTorch 框架为基础，向大家展示使用 MNIST 数据集训练神经网络模型的流程。\n",
    "\n",
    "由于 `torchvision.datasets.MNIST` 内置了 MNIST 数据集的读取接口，我们会直接调用：\n",
    "\n",
    "```Python\n",
    "from torchvision import datasets\n",
    "datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
    "```\n",
    "\n",
    "其中：\n",
    "- root：指的是下载路径，这里人工指定为你所需要的路径。\n",
    "- train：True就是训练集，False就是测试集\n",
    "- download：True指的是如果没有数据集则下载，如果有就不下载。\n",
    "- transform：指的是数据变换增强，比如翻转，拉伸等等。在这一步我们**先检查数据**，不使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=None)\n",
    "else:\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完毕后，检查一下数据集有多大，并且看看数据集训练集的第一条信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1F65FA15288>, 5)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(mnist_trainset[0])\n",
    "print(type(mnist_trainset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，数据集的训练集共有60000张图片，而测试集共有10000张图片。\n",
    "\n",
    "图片的类型都是 PIL.Image，以 tuple 形式保存。\n",
    "\n",
    "现在我们要读取测试集第一张图片 `mnist_testset[0]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的标签是：  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_zero, test_target_zero = mnist_testset[0]\n",
    "plt.imshow(test_image_zero, cmap ='gray')  # 灰度图像\n",
    "print(\"该图片的标签是： \",test_target_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知道，MNIST 数据集是灰度图像，而绘制出的结果也确实如此。上图展示的图片，很容易看出是一个手写的阿拉伯数字 “7”，分辨率是 $28\\times28$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "在下载完毕 MNIST 数据集以后，我们要如何将数据放入神经网络中呢？\n",
    "\n",
    "之前我们讲过，由于计算机的内存有限，在面对大规模数据集时不能一次性将所有数据放入模型进行训练，所以我们采用 mini-batch 的形式读取并训练数据集。\n",
    "\n",
    "所以现在我们的任务是创建一个**数据迭代器（Data Iterator）**，这个迭代器的作用是每次从数据集中挑选一定量的子集（mini-batch）放入神经网络进行训练，完成这一个 batch 的训练后再挑选另一个子集的数据继续训练。\n",
    "\n",
    "一个子集的大小叫做 “**batch size**”，它是一个超参数，具体的值需要根据显存（内存）大小来设置。\n",
    "\n",
    "### 数据迭代器 DataLoader\n",
    "\n",
    "PyTorch 已经为我们提供了这么一个数据迭代器类型，叫做`torch.utils.data.DataLoader`。有了这个 `DataLoader`，我们可以非常方便地把我们的数据以 mini-batch 的形式读取进来。\n",
    "\n",
    "首先我们来看看 [DataLoader] 的结构：\n",
    "\n",
    "```python\n",
    "torch.utils.data.DataLoader(dataset, \n",
    "                            batch_size=1, \n",
    "                            shuffle=False, \n",
    "                            sampler=None, \n",
    "                            batch_sampler=None, \n",
    "                            num_workers=0, \n",
    "                            collate_fn=None, \n",
    "                            pin_memory=False, \n",
    "                            drop_last=False, \n",
    "                            timeout=0, \n",
    "                            worker_init_fn=None, \n",
    "                            multiprocessing_context=None)\n",
    "```\n",
    "\n",
    "看起来 `Dataloader` 内的参数非常多，但是在这里我们只关注几个最重要的参数，其他参数在以后需要使用的时候再讲解。\n",
    "\n",
    "- **dataset** ([*Dataset*](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset)) – 我们将要读取的数据集。\n",
    "\n",
    "- **batch_size** (*int, optional*) – 每一个batch中要读取多少个数据 (default: 1)。\n",
    "\n",
    "- **shuffle** (*bool, optional*) – 在默认情况下，是按顺序进行采样的。如果要在每个 epoch 中随机打乱采样顺序，设置为`True` (default: False)。\n",
    "\n",
    "### Tensor 格式转换\n",
    "\n",
    "在 `torchvision.transforms` 模块中提供了非常多的图像变换、图像增强方法，包括亮度增强、拉伸缩放、旋转翻转等等。关于图像增强的方法，我们在此暂不涉及，这里我们仅仅采用 `transforms` 中的 `to_tensor()` 函数将 PIL 图像转变为 tensor 形式。\n",
    "\n",
    "`to_tensor()` 函数将每一张 $28\\times28$ 像素的手写数字图片中的灰度信息变为 tensor 的形式。 \n",
    "\n",
    "> **Tensor**，中文名叫**张量**，是包含单一数据类型的多维矩阵，和 NumPy 中的 `np.array()` 非常类似。在 TensorFlow 和 PyTorch 中主要采用的数据结构就是tensor。具体的，PyTorch Tensor 在 CPU 和 GPU 上各有9种数据类型，可以参见[TORCH.TENSOR](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)。\n",
    "\n",
    "我们尝试将测试集第一张图片 “7” 转换为 tensor 的形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
      "          0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
      "          0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "          0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
      "          0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
      "          0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
      "          0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
      "          0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
      "          0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
      "          0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
      "          0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
      "          0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(transforms.functional.to_tensor(test_image_zero).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在知道 `to_tensor()` 的工作原理之后，我们将数据转换为 tensor 并转入迭代器的步骤如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../datasets/MNIST/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "file2 = \"../datasets/MNIST/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "file3 = \"../datasets/MNIST/MNIST/raw/train-images-idx3-ubyte\"\n",
    "file4 = \"../datasets/MNIST/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "root = \"../datasets/MNIST/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经下载。\n"
     ]
    }
   ],
   "source": [
    "# PIL to Tensor\n",
    "data_tf = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 准备数据集\n",
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    print(\"已经下载。\")\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=False, transform=data_tf)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=False, transform=data_tf)\n",
    "else:\n",
    "    print(\"需要下载。\")\n",
    "    mnist_trainset = datasets.MNIST(root=root, train=True, download=True, transform=None)\n",
    "    mnist_testset = datasets.MNIST(root=root, train=False, download=True, transform=None) \n",
    "\n",
    "# 放入迭代器\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好了训练集和测试集的迭代器以后，我们就做好了数据的准备工作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络结构\n",
    "\n",
    "在 [3.01 神经网络与前向传播](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/03深度学习基础/3.01%20神经网络与前向传播.ipynb) 中，我们当时搭建了一个非常简单的三层神经网络，每一层神经元只有仅仅两三个。\n",
    "\n",
    "神经元的数量少，有利于我们推导前向传播公式，理解神经网络结构，但要解决真实问题却不太够。因此今天我们将要搭建一个神经元更多一些的三层神经网络，如下图：\n",
    "\n",
    "![三层网络](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/back_up_images/%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%A4%9A%E4%B8%AA%E7%A5%9E%E7%BB%8F%E5%85%83.png?raw=true)\n",
    "\n",
    "可以看到，在全连接层中，随着神经元的增加，神经网络变得更加复杂了起来。但是层数依旧是三层。\n",
    "\n",
    "> 需要注意的是，在输出层我们采用了 `softmax` 函数，以输出图像每个数字分类的概率。\n",
    "\n",
    "现在我们按照上图中的说明，正式开始搭建神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"定义神经网络Net\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化各个层\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播\"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查系统状态\n",
    "\n",
    "检查 PyTorch 版本和 GPU 状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.3.1\n",
      "Is CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch 版本： {torch.__version__}\")\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(\"GPU numbers: \", n_gpu)\n",
    "    print(\"device_name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器的设置\n",
    "\n",
    "首先，我们需要将定义好的神经网络模型放入 `device` 中，这个 `device` 之前已经由我们编程选择好了，如果电脑的GPU可用，则会选择放入GPU，如果不可用则会选择放入CPU。\n",
    "\n",
    "其次我们需要给神经网络选择一个优化器。之前我们学习过，普通的神经网络会最常见的的优化方法就是随机梯度下降法（Stochastic Gradient Descent，SGD），从而减小损失函数。因此这里我们也使用随机梯度下降法来作为我们的优化器。后续我们会讨论其他类型的优化器。\n",
    "\n",
    "> 实际上还有很多优化器，SGD 只是最常见的优化器之一。可以参见[TORCH.OPTIM](https://pytorch.org/docs/stable/optim.html?highlight=sgd#module-torch.optim)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(),    # 模型参数\n",
    "                      lr=0.03,               # 学习率\n",
    "                      momentum=0)            # 动量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练函数\n",
    "\n",
    "在设置完毕优化器之后，我们开始定义整个模型需要如何训练。\n",
    "\n",
    "#### model.train()\n",
    "\n",
    "需要了解的是，PyTorch 的模型在训练之前需要使用命令\n",
    "\n",
    "```python\n",
    "model.train()\n",
    "```\n",
    "\n",
    "来对模型开启训练模式。\n",
    "\n",
    "#### 将 mini-batch 数据放入device\n",
    "\n",
    "之前我们使用 `to(device)` 命令将模型放入了 device 中（这里 device 是 CPU）。我们还需要将训练数据和标签也放入 device 中。这样一来，模型和数据都在 device 中，我们的模型才能正常读取数据并训练。\n",
    "\n",
    "由于之前我们将数据和标签放入了一个迭代器中，所以要分批获取这些数据并放入 device 中。故这里需要使用一个 `for` 循环，按 batch_size 处理我们的数据。\n",
    "\n",
    "> **重要**：关于数据维度的变化：`data = data.view(data.shape[0], -1)` 的操作，将原本是 $28\\times28$ 的图像拉平（flatten）到了 $768$。因为在我们定义的神经网络中，第一层接受的是一个 $768$ 维的输入，而 data 原本的维度是 $1000\\times1\\times28\\times28$。\n",
    "\n",
    "#### 梯度归零\n",
    "\n",
    "在 PyTorch 训练过程中，每训练一个 batch 的数据，我们的优化器需要使用 `optimizer.zero_grad()` 进行梯度归零。回顾之前学习的梯度下降法，每次学习的梯度只对本 batch 数据负责，到了下一个 batch 我们又需要将梯度归零，然后重新计算梯度。\n",
    "\n",
    "如果不执行梯度归零，那么每个 batch 的梯度会累加起来，导致结果出错。\n",
    "\n",
    "#### 反向传播\n",
    "\n",
    "接下来我们定义损失函数。这里我们采用的是 [NLLLoss](https://pytorch.org/docs/stable/nn.functional.html?highlight=nll_loss#torch.nn.functional.nll_loss)，即 “Negative Log Likelihood loss”。它和之前的交叉熵损失函数（Cross Entropy Loss）是一回事。在 PyTorch 中，[torch.nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss) 结合了 `nn.LogSoftmax()` 和 `nn.NLLLoss()`。\n",
    "\n",
    "换句话说，`torch.nn.CrossEntropyLoss()` 会额外计算一次 softmax ，由于我们在网络的末尾定义了 log_softmax() 输出，所以只需要 `nn.NLLLoss()` 就足够了。\n",
    "\n",
    "最后我们要记得使用 `optimizer.step()` 更新模型的参数。[torch.optim.Optimizer.step](https://pytorch.org/docs/stable/optim.html?highlight=optimizer%20step#torch.optim.Optimizer.step) 表示单步（一个 batch 的数据）更新模型的参数。\n",
    "\n",
    "#### 打印 loss 值\n",
    "\n",
    "有时候我们需要在训练过程中看看模型的 loss 是否在下降，所以采用打印 loss 的方式来观察，简单有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(data.shape[0], -1)  # 从 28*28 转换为 768\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset)}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316802\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.272415\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.236447\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.186664\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.143221\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.077999\n",
      "\n",
      "Test set: Average loss: 2.0159156616210936, Accuracy: 6224/10000 (62.24%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.013845\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.945199\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.877959\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.772789\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.675168\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.557665\n",
      "\n",
      "Test set: Average loss: 1.4325026123046876, Accuracy: 6807/10000 (68.07%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.440722\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.355411\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.268090\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.164411\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.108160\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.032516\n",
      "\n",
      "Test set: Average loss: 0.9420964782714843, Accuracy: 7766/10000 (77.66%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.940326\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.898359\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.861257\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.828206\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.757919\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.736625\n",
      "\n",
      "Test set: Average loss: 0.7111946838378906, Accuracy: 8224/10000 (82.24%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.728172\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.691363\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.660644\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.678021\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.648010\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.593013\n",
      "\n",
      "Test set: Average loss: 0.593717236328125, Accuracy: 8420/10000 (84.2%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.639741\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.588251\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.581666\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.582823\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.587827\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.556442\n",
      "\n",
      "Test set: Average loss: 0.5243825744628906, Accuracy: 8572/10000 (85.72%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.514003\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.518734\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.511532\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.529290\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.508841\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.494326\n",
      "\n",
      "Test set: Average loss: 0.47778785095214843, Accuracy: 8701/10000 (87.01%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.475078\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.484051\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.462017\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.510331\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.464790\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.521813\n",
      "\n",
      "Test set: Average loss: 0.44532625122070313, Accuracy: 8790/10000 (87.9%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.456885\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.469442\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.469008\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.442491\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.451502\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.455629\n",
      "\n",
      "Test set: Average loss: 0.42077213134765623, Accuracy: 8844/10000 (88.44%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "#if (args.save_model):\n",
    "#    torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html?highlight=save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "output_dir = \"./model_3.04_save\"\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "torch.save(model_to_save.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
