{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔可夫模型（HMM）\n",
    "\n",
    "作者：杨岱川\n",
    "\n",
    "时间：2019年10月\n",
    "\n",
    "github：https://github.com/DrDavidS/basic_Machine_Learning\n",
    "\n",
    "开源协议：[MIT](https://github.com/DrDavidS/basic_Machine_Learning/blob/master/LICENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 隐马尔可夫模型的基本概念\n",
    "\n",
    "隐马尔可夫模型（hidden Markov model）是可以用于标注问题的统计学习模型，描述由隐藏的的马尔可夫链随机生成观测序列的过程，属于生成模型。\n",
    "\n",
    "### 隐马尔可夫模型定义\n",
    "\n",
    "隐马尔可夫模型的形式定义如下：\n",
    "\n",
    ">设 $Q$ 是所有可能的状态的集合，$V$ 是所有可能的观测的集合：\n",
    ">\n",
    ">$$\\large Q=\\{q_1,q_2,\\cdots,q_N\\},\\quad V=\\{v_1.v_2,\\cdots,v_M\\}$$\n",
    ">\n",
    ">其中，$N$ 是可能的状态的集合，$M$ 是可能的观测数。\n",
    ">\n",
    ">$I$ 是长度为 $T$ 的状态序列，$O$ 是对应的观测序列：\n",
    ">\n",
    ">$$\\large I=(i_1,i_2,\\cdots,i_T),\\quad O=(o_1,o_2,\\cdots,o_T)$$\n",
    ">\n",
    ">$A$ 是**状态转移矩阵**：\n",
    ">\n",
    ">$$\\large A=\\left[a_{ij}\\right]_{N\\times N}$$\n",
    ">\n",
    ">其中，\n",
    ">\n",
    ">$$\\large a_{ij}=P(i_{t+1}=q_j|i_t=q_i),\\quad i=1,2,\\cdots,N;\\quad j=1,2,\\cdots,N$$\n",
    ">\n",
    ">表示在时刻 $t$ 处于 $q_i$ 状态的条件下，在时刻 $t+1$ 转移到 $q_j$ 状态的概率。\n",
    ">\n",
    ">$B$ 是**概率转移矩阵**：\n",
    ">\n",
    ">$$\\large B=\\left[b_j(k)\\right]_{N\\times M}$$\n",
    ">\n",
    ">其中，\n",
    ">\n",
    ">$$\\large b_j(k)=P(o_t=v_k|i_t=q_j),\\quad k=1,2,\\cdots,M;\\quad j=1,2,\\cdots,N$$\n",
    ">\n",
    ">是在时刻 $t$ 处于状态 $q_j$ 的条件下生成观测 $v_k$ 的概率。\n",
    ">\n",
    ">$\\pi$ 是**初始状态概率向量**：\n",
    ">\n",
    ">$$\\large \\pi = (\\pi_i)$$\n",
    ">\n",
    ">其中，\n",
    ">\n",
    ">$$\\large \\pi_i=P(i_1=q_i),\\quad i=1,2,\\cdots,N$$\n",
    ">\n",
    ">是时刻 $t=1$ 处于状态 $q_i$ 的概率。\n",
    ">\n",
    ">隐马尔可夫模型由初始状态概率向量 $\\pi$、状态转移概率矩阵 $A$ 和观测概率矩阵 $B$ 决定。$\\pi$ 和 $A$ 决定状态序列，$B$ 决定观测序列。因此，隐马尔可夫模型 $\\lambda$ 可以用三元符号表示，即\n",
    ">\n",
    ">$$\\large \\lambda = (A,B,\\pi)$$\n",
    ">\n",
    ">$A,B,\\pi$ 成为隐马尔可夫模型的三要素。\n",
    "\n",
    "隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隐马尔可夫模型的假设\n",
    "\n",
    "从定义可知，隐马尔可夫模型有两个基本假设：\n",
    "\n",
    "- 其次马尔科夫性假设：\n",
    "\n",
    "假设隐藏的马尔可夫链在任意时刻 $t$ 的状态只依赖其**前一时刻的状态**，与其他时刻的状态以及观测无关，也与时刻 $t$ 无关：\n",
    "\n",
    "$$\\large P(i_t|i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(i_t|i_{t-1}),\\quad t=1,2,\\cdots,T$$\n",
    "\n",
    "- 观测独立性假设：\n",
    "\n",
    "假设在任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关：\n",
    "\n",
    "$$\\large P(o_t|i_{T},o_{T},i_{T-1},o_{T-1},\\cdots,i_{t+1},o_{t+1},i_{t},i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(o_t|i_t)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子解释\n",
    "\n",
    "李航《统计学习方法》书上有相关的例子，这里我们还可以用其他例子来说明状态转移矩阵，[参考链接](https://blog.csdn.net/zxm1306192988/article/details/78595933)。\n",
    "\n",
    ">- 例1\n",
    ">\n",
    ">假设我手里有三个不同的骰子。 \n",
    ">\n",
    ">第一个骰子有六个面（称这个骰子为 $\\rm D6$），每个面$(1，2，3，4，5，6)$出现的概率是 $\\frac{1}{6}$。 \n",
    ">\n",
    ">第二个骰子是个四面体（称这个骰子为 $\\rm D4$），每个面$(1，2，3，4)$出现的概率是 $\\frac{1}{4}$。 \n",
    ">\n",
    ">第三个骰子有八个面（称这个骰子为 $\\rm D8$），每个面$(1，2，3，4，5，6，7，8)$出现的概率是 $\\frac{1}{8}$。\n",
    ">\n",
    ">![img](https://img-blog.csdn.net/20171121220512952)\n",
    "\n",
    "假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是$\\frac{1}{3}$，这步相当于确定初始概率向量 $\\pi$。\n",
    "\n",
    "![img](https://img-blog.csdn.net/20171121221604169)\n",
    "\n",
    "然后我们掷骰子，得到一个数字，“1，2，3，4，5，6，7，8” 中的一个。\n",
    "\n",
    "不停的重复上述过程，我们会得到一串数字，每个数字都是 “1，2，3，4，5，6，7，8” 中的一个。\n",
    "\n",
    "其中，这串数字叫做**可见状态链**，而使用的骰子的顺序就是**隐含状态链**，我们观察不到使用骰子的顺序。\n",
    "\n",
    "其实，三个骰子的观测概率分布 $B$ 可以表示为：\n",
    "\n",
    "$$\n",
    "\\large\n",
    "B=\n",
    "\\begin{bmatrix}\n",
    "0.166 & 0.166  & 0.166  & 0.166  & 0.166  & 0.166 & 0 & 0\\\\\n",
    "0.25 & 0.25 & 0.25 & 0.25 & 0 & 0 & 0 & 0\\\\\n",
    "0.125 & 0.125 & 0.125 & 0.125 & 0.125 & 0.125 & 0.125 & 0.125\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "明显，其中行表示具体骰子，列表示从1到8的点数的概率。\n",
    "\n",
    "而状态转移矩阵 $A_1$ 表示选择三个骰子的概率，之前已经有过描述，是随机选择的。故有\n",
    "\n",
    "$$\n",
    "\\large\n",
    "A_1=\n",
    "\\begin{bmatrix}\n",
    "0.333 & 0.333  & 0.333 \\\\\n",
    "0.333 & 0.333 & 0.333 \\\\\n",
    "0.333 & 0.333 & 0.333\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "假设我们新定一个规则 $A_2$，当前骰子投出之后不能在下一次继续投掷，只能随机选择另外两个骰子之一投掷，则状态转移矩阵 $A_2$ 变为：\n",
    "\n",
    "$$\n",
    "\\large\n",
    "A_2=\n",
    "\\begin{bmatrix}\n",
    "0 & 0.5  & 0.5 \\\\\n",
    "0.5 & 0 & 0.5 \\\\\n",
    "0.5 & 0.5 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "有如上例子可以帮助理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率计算算法\n",
    "\n",
    "### 直接计算法\n",
    "\n",
    "直接计算法在概念上可行，但是在计算上是不可行的。\n",
    "\n",
    "给定模型 $\\lambda = (A,B,\\pi)$ 和 观测序列 $O=(o_1,o_2,\\cdots,o_T)$，计算观测序列 $O$ 出现的概率 $P(O|\\lambda)$。最直接的方法就是按照概率公式直接计算。通过列举所有可能的长度为 $T$ 的状态序列 $I=(i_1,i_2,\\cdots,i_T)$，求各个状态序列 $I$ 与观测序列 $O=(o_1,o_2,\\cdots,o_T)$ 的联合概率 $P(O,I|\\lambda)$，然后对所有的状态序列求和，得到 $P(O|\\lambda)$。\n",
    "\n",
    "此方法可以参见书本第10.2.1节，不做详解。\n",
    "\n",
    "该方法计算量很大，是 $O(TN^T)$ 阶的，不可行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前向算法\n",
    "\n",
    "定义前向概率：\n",
    "\n",
    ">给定隐马尔可夫模型 $\\lambda = (A,B,\\pi)$，定义到时刻 $t$ 部分观测序列为 $(o_1,o_2,\\cdots,o_T)$，且状态为 $q_i$ 的概率为前向概率，记作\n",
    ">\n",
    ">$$\\large \\alpha_t(i)=P(o_1,o_2,\\cdots,o_t,i_t=q_i|\\lambda) $$\n",
    "\n",
    "可以递推地求得前向概率 $\\alpha_t(i)$ 及观测概率 $P(O|\\lambda)$。\n",
    "\n",
    "观测序列概率的前向算法为：\n",
    "\n",
    "输入：隐马尔可夫模型 $\\lambda$，观测序列 $O$；\n",
    "\n",
    "输出：观测序列概率 $P(O|\\lambda)$。\n",
    "\n",
    "（1）**初值**\n",
    "\n",
    "$$\\large \\alpha_1(i)=\\pi_ib_i(o_1), \\quad i=1,2,\\cdots,N$$\n",
    "\n",
    "其中 $b_i(o_i)$ 指的是在初始隐藏状态  $i$ 下，当前观测序列为 $o_1$ 时的观测概率分布。\n",
    "\n",
    "$\\pi_i$ 指的是在初始隐藏状态为 $i_1=q_i$ 的概率。\n",
    "\n",
    "（2）**递推**\n",
    "\n",
    "在下一个时间步有\n",
    "\n",
    "$$\\large \\alpha_2(i)=\\left[  \\sum^N_{j=1}\\alpha_1(j)a_{ji} \\right]b_i(o_2)$$\n",
    "\n",
    "其中 $\\alpha_1(j)$ 指的是在第一时间步 $t=1$ 时观测到 $o_1$，并且在 $t=1$ 时刻处于状态 $q_j$ 的前向概率。\n",
    "\n",
    "而 $\\alpha_1(j)a_{ji}$ 就是在第一时间步观测为 $o_1$，并且从第一时间步到第二时间步状态从 $q_j$ 到 $q_i$ 的联合概率。\n",
    "\n",
    "对所有的 $N$ 个状态 $q_j$ 求和，结果就是第一时间步观测为 $o_1$ 并在 第二时间步处于状态 $q_i$ 的联合概率。\n",
    "\n",
    "对 $t=1,2,\\cdots,T-1$\n",
    "\n",
    "$$\\large \\alpha_{t+1}(i)=\\left[ \\sum^N_{j=1}\\alpha_t(j)a_{ji} \\right]b_i(o_{t+1}),\\quad i=1,2,\\cdots,N $$\n",
    "\n",
    "（3）**终止**\n",
    "\n",
    "由于\n",
    "\n",
    "$$\\large \\alpha_T(i)=P(o_1,o_2,\\cdots,o_T,i_T=q_i|\\lambda)$$\n",
    "\n",
    "所以\n",
    "\n",
    "$$\\large P(O|\\lambda)=\\sum^N_{i=1}\\alpha_T(i)$$\n",
    "\n",
    "前向算法减少计算量的原因在于每一次计算直接引用前一个时刻的计算结果，避免了重复计算。利用前向概率计算 $P(O|\\lambda)$ 的复杂度就是 $O(N^2T)$，比直接法的 $O(TN^T)$ 小得多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后向算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率与期望的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习算法\n",
    "\n",
    "### 监督学习方法\n",
    "\n",
    "假设已给训练数据中包含 $S$ 个长度相同的观测序列和对应的状态序列 $\\lbrace(O_1,I_1),(O_2,I_2),\\cdots,(O_S,I_S)\\rbrace$，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。\n",
    "\n",
    "如下：\n",
    "\n",
    "1. 转移概率 $a_{ij}$ 的估计\n",
    "\n",
    "设样本中时刻 $t$ 处于状态 $i$，时刻 $t+1$ 转移到状态 $j$ 的频数为 $A_{ij}$，那么状态转移概率 $a_{ij}$ 的估计是\n",
    "\n",
    "$$\\large \\hat a_{ij} = \\frac{A_{ij}}{\\sum^N_{j=1}A_{ij}}, \\quad i=1,2,\\cdots,N; \\quad j=1,2,\\cdots,N$$\n",
    "\n",
    "2. 观测概率 $b_j(k)$ 的估计\n",
    "\n",
    "3. 初始状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
